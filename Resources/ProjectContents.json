[
    {
        "name" : "(WIP) VR Training House", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "Currently being developed as part of a 10-week placement (starting 17/01/22) at the Lancashire Constabulary, using Unity 2021, C#, and the XR Interaction Toolkit, with support for all common 6DOF VR headsets."
            },
            {
                "text" : "Currently the key features are:",
                "list" : [
                    { "item": "Beskope systems for intuitive interactions using a variety of digital devices" },
                    { "item" : "Automated and dynamic creation of Q&A UI elements" },
                    { "item" : "Accessible VR gameplay" },
                    { "item" : "Animated interactions with realistic digital devices"},
                    { "item" : "Performance scoring and review systems" }
                ]
            },
            { 
                "heading": "Project Description",
                "subheading" : "Gameplay / Device Interactions",
                "text" : "Currently, the project offers several unique and animated interactions with various digital objects, for instance turning devices on/off, browsing their contents, etc. ",
                "imageSrc" : "./Images/Tablet.gif",
                "imageAlt" : ""
            },
            { 
                "text" : "To make the interactions as accessible as possible, I have developed an interaction UI system which allows users to navigate the UI / interact with devices in multiple ways, using: ",
                "list" : [
                    { "item" : "Controller's joytick and buttons" },
                    { "item": "Controller's triggers" },
                    { "item" : "Raycast from the other hand/controller" }
                ],
                "imageSrc" : "./Images/Tablet.gif",
                "imageAlt" : ""
            },
            {
                "text" : "Officers are graded on their performance in multiple ways, with the primary metric being their responses to a set of device oriented questions. The UI for these questions are automatically populated and made functional using custom code and scriptable objects.",
                "imageSrc" : "./Images/Question Interaction.gif",
                "imageAlt" : ""
            },
            { 
                "text" : "Officers are also able to review their performance in-game, utilising various (interactable) UI elements, with these UI elements being automatically updated based on the users performance.",
                "imageSrc" : "./Images/Questions.gif",
                "imageAlt" : "" 
            },
            { 
                "text" : "In the future, several more features are planned, for instance:",
                "list" : [
                    { "item" : "Realistic VR house environment" },
                    { "item" : "Physically based door, cupboard, and draw interactions" },
                    { "item" : "Dynamic and randomised placement of key objects and digital items" },
                    { "item" : "Performance report generation used for ISO accreditation" },
                    { "item" : "Oculus Quest/Quest 2 Standalone application"},
                    { "item" : "(3DOF) Pico G2 Port" }
                ]
            }
        ]
    },


    {
        "name" : "(WIP) Unreal Brawler Project", 
        "content" : [
            { 
                "heading" : "Overview",
                "text" : "This project was created as part of a four-person team using Unreal Engine 4, with my responsibilities primarily being: ",
                "list" : [
                    { "item" : "Developing the AI systems (using behaviour trees and blackboards)" },
                    { "item" : "Developing the backend animation systems" },
                    { "item" : "Developing the UI systems" },
                    { "item" : "Refining the gameplay systems" }
                ]
            },
            {
                "text" : "I was responsible for creating the AI systems, which makes use of an custom AI controller, behaviour trees, blackboards, and well as code written in both C++ and blueprints. ",
                "video" : "https://www.youtube.com/embed/O9Tb0yvup7M?"
            },
            {
                "text" : "I was also responsible for creating the UI and the animations systems (animation controllers, blend spaces, etc.), for both the player and AI.",
                "video" : "https://www.youtube.com/embed/Ja5FeJKe57I?"
            },
            {
                "subheading" : "AI Systems",
                "text" : "The AI exhibit custom behaviour depending on a set of criteria, with the AI being able to:",
                "list" : [
                    { "item" : "Patrol the environment" },
                    { "item" : "Intercept and flank the player when attacking" },
                    { "item" : "Investigate the player's last known position on sight loss" },
                    { "item" : "Make smart decisions whether to attack the player or objective" },
                    { "item" : "Spread out when attacking objectives to increase believability and challenge" }
                ]
            },
            {
                "subheading" : "Animation Systems",
                "text" : "For the character controller, we were heavily inspired by Overgrowth's procedural animation systems (with I initially experimenting using procedural animation early on in the project). With the final animation system I developed making use of: ",
                "list" : [
                    { "item" : "Blueprints (event graph)" },
                    { "item" : "Animation state machines" },
                    { "item" : "1D & 2D blend spaces" }
                ]
            },
            {
                "subheading" : "UI Systems",
                "text" : "With the UI I developed for this project including:", 
                "list" : [
                    { "item" : "Player HUD (including the player's and objective's text and health bars)" },
                    { "item" : "Main menu" },
                    { "item" : "Pause menu" },
                    { "item" : "Basic settings & graphics menus" }
                ]
            }
        ]
    },
    

    {
        "name" : "3D Object Manipulation for Mobile AR (BSc Project)", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This project forms the basis for the research paper I submitted to an international conference, as well as my BSc dissertation. It is primarily concerned with allowing 3D objects in AR to be manipulated with Six Degrees-Of-Freedom (6DOF) using simple touch gestures, without scarficiing granular control. The key aspects of this project are:",
                "list" : [
                    { "item" : "Novel interaction system using touch gestures and the user's position to determine the interaction and interaction axis" },
                    { "item" : "Custom encoding and input recognition systems for touch gestures" },
                    { "item" : "A conversion of the touch gestures to UI elements - supporting the same interactions" },
                    { "item": "Two unique evaluation applications" }
                ]
            },
            {
                "heading" : "Project Description",
                "subheading" : "Touch Gesture Input Encoding and Recognition",
                "text" : "The interaction system is unique in the fac that it supports 6DOF manipulation using simple touch gestures, and that it uses the user's perspective of the object to determine the axes that the user can manipulate the object on.",
                "video" : "https://www.youtube.com/embed/_6X1hycDETM?"
            },
            {
                "text" : "I developed a bespoke system to encode and recognise unique touch gestures (as this was developed before the official release of Unity's new input system), with my system supporting: ",
                "list" : [
                    {"item" : "Tapping" },
                    {"item" : "Tapping and holding" },
                    {"item" : "Dragging / swiping" },
                    {"item" : "Pinching" }
                ]
            },
            {
                "text" : "Which allow for the 3D object to be translated, rotated, and scaled on all axis, using the same gestures. With translation and rotation supporting verbose and granular interactions with two different gestures. "
            },
            {
                "subheading" : "UI Input Method & Evaluation",
                "text" : "For a comparative evaluation, I developed a UI system which made use of the user's position, but instead utilised UI elements instead of touch gestures to perform the interactions. ",
                "video" : "https://www.youtube.com/embed/K8WMOohHseQ?"
            },
            {
                "text" : "The evaluation of the input methods made use of a “Simon says” style game, where users were timed when performing a randomised interaction (e.g. moving the object into a square on the screen), using each of the interaction methods"
            },
            {
                "text" : "Initially I also developed an application which recorded the user's touch gestures when performing a given interaction (e.g. scaling), and outputted as JSON file containing the number of fingers and the position each frame of the fingers. With this being used to help encode the gestures used by the interaction system."
            },
            {
                "text" : "With the animations the users were viewing to perform their gestures to being shown below.",
                "imageSrc" : "./Images/All GES Tasks.gif",
                "imageAlt" : ""
            }
        ]
    },
    {
        "name" : "Unreal Engine 4 & C++ Course", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : ""
            }
        ]
    },


    {
        "name" : "Unity RPG Combat Creator Course", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This was an exploration into developing a website from scratch using HTML, CSS, and JS, without making use of frameworks such as Bootstrap or JQuery. The most unique aspect about the site is that it utilises two JSON files to store and dynamically create new project cards, and their content, making adding new projects to the site far easier."
            }
        ]
    },


    {
        "name" : "Portfolio Website", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This was an exploration into developing a website from scratch using HTML, CSS, and JS, without making use of frameworks such as Bootstrap or JQuery. The most unique aspect about the site is that it utilises two JSON files to store and dynamically create new project cards, and their content, making adding new projects to the site far easier."
            },
            {
                "text" : "The website is currently being hosted using GitHub Pages and is linked to a custom domain \"DanHarris.Online\". Testing before deployment is done using node.js and the \"live-server\" addon."
            },
            { 
                "heading": "Project Description",
                "text" : "I decided to not use any web frameworks or cite builders to build this website as I thought it would be an interesting challenge and allow me to improve my knowledge of HTML, CSS and JS. The website is inspired by several other portfolio sites, with the design and layout also being heavily influenced by that of the Steam Deck website."    
            },
            { 
                "text" : "The most notable aspect to the website is its dynamic loading of project data, with all project cards, and their content being loaded from two JSON files. A JS script I developed parses the JSON files and automatically creates the project cards and its contents (displayed in the modal), with the idea being to make adding new projects to the website a painless process.",
                "video" : "https://www.youtube.com/embed/KwUOzOsLVMQ?"
            },
            {
                "text" : "Whilst it currently is at an acceptable state, I still plan on improving the code as well as iterating upon its design and functionality. For instance, I intended for the dynamic project loading to allow for even more elements and an even more flexible design of the project card / contents. I also plan on creating the functionality for me to upload a text file and for the website automatically parse it and add it to its respective JSON file, making the addition of projects even easier."
            }
        ]
    }
]
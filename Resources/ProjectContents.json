[
    {
        "name" : "VR Police Training Experience", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "Recently completed as part of a 10-week Placement (January-March 2022) at the Lancashire Constabulary. The project was developed using Unity 2021.2, C#, and the XR Interaction Toolkit, and supports all common (6DOF) VR headsets, including a dedicated Oculus Quest 2 port."
            },
            {
                "text" : "The experience includes:",
                "list" : [
                    { "item": "A bespoke interaction system supporting 25 unique interactions for 10 digital devices" },
                    { "item" : "A custom Q&A system with multiple question types and the dynamic creation of UI elements" },
                    { "item" : "Accessible and intuitive VR gameplay - teleporting, smooth locomotion, snap turning, etc." },
                    { "item" : "Physics-based interactions with furniture" },
                    { "item" : "Performance scoring and review systems (for ISO accreditation)" },
                    { "item" : "Randomised device spawning at pre-defined locations" },
                    { "item" : "A realistic house environment" }
                ]
            },
            { 
                "heading": "Project Description",
                "subheading" : "Gameplay / Device Interactions",
                "text" : "The experience offers 25+ unique and animated interactions with 10 of digital devices, for instance, turning devices on/off, covering objects, browsing their contents, etc. ",
                "video" : "./Videos/VR House Device Interaction.mp4"
            },
            { 
                "text" : "To create accessible interactions, I developed a UI system which enables users to navigate the UI / interact with devices in multiple ways, for example, using: ",
                "list" : [
                    { "item" : "Controller's joystick and buttons" },
                    { "item" : "Controller's triggers" },
                    { "item" : "Raycast from the other hand/controller" }
                ]
            },
            {
                "text" : "Physics-based interactions play a key part in the experience, with officers needing to open doors, cupboards, and drawers to locate various digital devices. With all these interactions being driven using Unity's physics system.",
                "video" : "./Videos/VR House Physics Interactions 720p.mp4"
            },
            {
                "text" : "I also created a bespoke Q&A system to test officers' knowledge, with the system supporting:",
                "list" : [
                    { "item" : "Dynamic creation of UI elements based on (designer friendly) scriptable objects" },
                    { "item" : "Support for single answer and multiple answer questions" },
                    { "item" : "Randomised placement of answers" },
                    { "item" : "Variations for grabbable and static digital devices" }
                ],
                "video" : "./Videos/VR House Q&A UI 720p.mp4"
            },  
            {
                "text" : "To make this system designer friendly, all question and answer data is read from scriptable objects which are easily altered by a designer"
            },
            {
                "text" : "Digital devices are spawned randomly at one of several pre-determined locations, encouraging officers to thoroughly investigate the environment",
                "video" : "./Videos/VR House Spawning 720p.mp4"
            },
            { 
                "text" : "A report is generated based off the officers performance within the experience (for ISO accreditation). This report is constantly updated throughout, and is stored on the device, with officers also having the option to review it in-game. The report includes:",
                "list" : [
                    { "item" : "The number of correctly answered questions" },
                    { "item" : "The incorrect response(s) the officers gave to a given question, and what its correct answers are" },
                    { "item" : "The time taken to complete the experience" },
                    { "item" : "The amount of 'hidden' digital devices discovered" }
                ],
                "video" : "./Videos/VR House Question Review.mp4"
            }
        ]
    },

    {
        "name" : "(WIP) Unreal Brawler Project", 
        "content" : [
            { 
                "heading" : "Overview",
                "text" : "This project was created as part of a four-person team using Unreal Engine 4, with my responsibilities primarily being: ",
                "list" : [
                    { "item" : "Developing the AI systems (using behaviour trees and blackboards)" },
                    { "item" : "Developing the backend animation systems" },
                    { "item" : "Developing the UI systems" },
                    { "item" : "Refining the gameplay systems" }
                ]
            },
            {
                "text" : "I was responsible for creating the AI systems, which makes use of an custom AI controller, behaviour trees, blackboards, and well as custom behaviour tree tasks and services written in both C++ and blueprints.",
                "video" : "https://www.youtube.com/embed/O9Tb0yvup7M?"
            },
            {
                "text" : "I was also responsible for creating the UI and the animations systems (animation controllers, blend spaces, etc.), for both the player and AI.",
                "video" : "https://www.youtube.com/embed/Ja5FeJKe57I?"
            },
            {
                "subheading" : "AI Systems",
                "text" : "The AI exhibit custom behaviour depending on a set of criteria, with the AI being able to:",
                "list" : [
                    { "item" : "Patrol the environment" },
                    { "item" : "Intercept and flank the player when attacking" },
                    { "item" : "Investigate the player's last known position on sight loss" },
                    { "item" : "Make smart decisions whether to attack the player or objective" },
                    { "item" : "Spread out when attacking objectives to increase believability and challenge" }
                ]
            },
            {
                "subheading" : "Animation Systems",
                "text" : "For the character controller, we were heavily inspired by Overgrowth's procedural animation systems (with I initially experimenting using procedural animation early on in the project). With the final animation system I developed making use of: ",
                "list" : [
                    { "item" : "Blueprints (event graph)" },
                    { "item" : "Animation state machines" },
                    { "item" : "1D & 2D blend spaces" }
                ]
            },
            {
                "subheading" : "UI Systems",
                "text" : "With the UI I developed for this project including:", 
                "list" : [
                    { "item" : "Player HUD (including the player's and objective's text and health bars)" },
                    { "item" : "Main menu" },
                    { "item" : "Pause menu" },
                    { "item" : "Basic settings & graphics menus" }
                ]
            }
        ]
    },
    {
        "name" : "3D Object Manipulation for Mobile AR (BSc Project)", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This project forms the basis for the research paper I submitted to an international conference, as well as my BSc dissertation. It is primarily concerned with allowing 3D objects in AR to be manipulated with Six Degrees-Of-Freedom (6DOF) using simple touch gestures, without sacrificing granular control. The key aspects of this project are:",
                "list" : [
                    { "item" : "Novel interaction system using touch gestures and the user's position & orientation" },
                    { "item" : "Custom encoding and input recognition systems for touch gestures" },
                    { "item" : "Translation, rotation, and scaling on all 3 axes" },
                    { "item" : "A conversion of the touch gestures to UI elements - supporting the same interactions" },
                    { "item": "Two unique evaluation applications" }
                ]
            },
            {
                "heading" : "Project Description",
                "subheading" : "Touch Gesture Input Encoding and Recognition",
                "video" : "https://www.youtube.com/embed/_6X1hycDETM?"
            },
            {
                "text" : "The interaction system is unique in the fact that it supports 6DOF manipulation using simple touch gestures, and that it uses the user's perspective of the object to determine the axes that the user can manipulate the object on."
            },
            {
                "text" : "I developed a bespoke system to encode and recognise unique touch gestures (as this was developed before the official release of Unity's new input system), with my system supporting: ",
                "list" : [
                    {"item" : "Tapping" },
                    {"item" : "Tapping and holding" },
                    {"item" : "Dragging / swiping" },
                    {"item" : "Pinching" }
                ]
            },
            {
                "text" : "Which allow for the 3D object to be translated, rotated, and scaled on all axis, using the same gestures. With translation and rotation supporting verbose and granular interactions with two different gestures. "
            },
            {
                "subheading" : "UI Input Method & Evaluation",
                "text" : "For a comparative evaluation, I developed a UI system which made use of the user's position, but instead utilised UI elements instead of touch gestures to perform the interactions. ",
                "video" : "https://www.youtube.com/embed/K8WMOohHseQ?"
            },
            {
                "text" : "The evaluation of the input methods made use of a “Simon says” style game, where users were timed when performing a randomised interaction (e.g. moving the object into a square on the screen), using each of the interaction methods"
            },
            {
                "text" : "Initially I also developed an application which recorded the user's touch gestures when performing a given interaction (e.g. scaling), and outputted as JSON file containing the number of fingers and the position each frame of the fingers. With this being used to help encode the gestures used by the interaction system."
            },
            {
                "text" : "With the animations the users were viewing to perform their gestures to being shown below.",
                "imageSrc" : "./Images/All GES Tasks.gif",
                "imageAlt" : ""
            }
        ]
    },

    {
        "name" : "Portfolio Website", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This was an exploration into developing a website from scratch using HTML, CSS, and JS, without making use of frameworks such as Bootstrap or JQuery. The most unique aspect about the site is that it utilises two JSON files to store and dynamically create new project cards, and their content, making adding new projects to the site far easier."
            },
            {
                "text" : "The website is currently being hosted using GitHub Pages and is linked to a custom domain \"DanHarris.Online\". Testing before deployment is done using node.js and the \"live-server\" addon."
            },
            { 
                "heading": "Project Description",
                "text" : "I decided to not use any web frameworks or cite builders to build this website as I thought it would be an interesting challenge and allow me to improve my knowledge of HTML, CSS and JS. The website is inspired by several other portfolio sites, with the design and layout also being heavily influenced by that of the Steam Deck website."    
            },
            { 
                "text" : "The most notable aspect to the website is its dynamic loading of project data, with all project cards, and their content being loaded from two JSON files. A JS script I developed parses the JSON files and automatically creates the project cards and its contents (displayed in the modal), with the idea being to make adding new projects to the website a painless process.",
                "video" : "https://www.youtube.com/embed/KwUOzOsLVMQ?"
            },
            {
                "text" : "Whilst it currently is at an acceptable state, I still plan on improving the code as well as iterating upon its design and functionality. For instance, I intended for the dynamic project loading to allow for even more elements and an even more flexible design of the project card / contents. I also plan on creating the functionality for me to upload a text file and for the website automatically parse it and add it to its respective JSON file, making the addition of projects even easier."
            }
        ]
    },

    {
        "name" : "Unreal Engine 4 & C++ Course", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This course gave me a solid understanding of many C++ and Unreal Engine 4 principles, which I then took further to future projects. The coursed touched on several key areas such as:",
                "list" : [
                    { "item" : "Unreal tools and Unreal specific C++" },
                    { "item" : "Player input handling and developing gameplay features" },
                    { "item" : "Basic AI using behaviour trees, blackboards, and C++ Tasks / Services" },
                    { "item" : "Working with high-quality assets" }
                ],
                "imageSrc" : "./Images/UECourse Combat.gif" 
            },
            {
                "heading" : "Course Content",
                "subheading" : "Final Game",
                "text" : "The final game developed as part of this project was a third-person shooter, which focused on creating a complete experience using high-quality assets, where the player must fight through a level filled with AI. This game included:",
                "list" : [
                    { "item" : "Movement mechanics" },
                    { "item" : "Shooting mechanics (raycasting, hit detection, sounds, and visuals)" },
                    { "item" : "Keyboard & mouse / controller input" },
                    { "item" : "AI which shoot the player and investigate on sight loss" },
                    { "item" : "Working with animations, and creating blend spaces, using aim offsets, etc." }
                ],
                "imageSrc" : "./Images/UECourse Movement.gif"
            },
            {
                "subheading" : "Other Games",
                "text" : "The course had several other game projects to complete, which covered several topics such as diving into the fundamentals of character movement. With one game being to create a basic tank character, and stationary AI that rotate to shoot projectiles at the player.",
                "imageSrc" : "./Images/UECourse Tank.gif"
            },
            {
                "subheading" : "Course Takeaways",
                "text" : "Completing the course gave me an solid understanding of how to develop games using Unreal Engine 4, which I have subsequently improved by developing more games within Unreal Engine 4 (e.g. the Unreal Brawler game). The course taught me how to program gameplay systems within Unreal Engine, using C++, as well as how to integrate these gameplay systems with other aspects of the project, such as AI, UI, animations, etc."
            }
        ]
    },

    {
        "name" : "Unity RPG Combat Creator Course", 
        "content" : [
            { 
                "heading": "Overview",
                "text" : "This course was focused on teaching more advanced game development topics and programming patterns, with a focus on creating clean, optimised, and maintainable code. Some of the topics covered include:",
                "list" : [
                    { "item" : "Using scriptable objects to define weapons, enemy classes, and player progression" },
                    { "item" : "Following programming patterns and best practices, (e.g. avoiding circular dependencies, using singletons, the observer pattern, etc.)" },
                    { "item" : "AI using custom behaviour" },
                    { "item" : "Player and AI movement using nav meshes" }
                ],
                "imageSrc" : "./Images/RPG Bow Combat.gif"
            },
            {
                "heading" : "Course Content",
                "text" : "The game created when following this course is a Diablo style RPG, using mouse controls, to move around, pick-up objects and attack enemies. With the key features of the game including:",
                "list" : [
                    { "item" : "A combat system which supports multiple weapons and animations, including both melee and projectiles" },
                    { "item" : "Player progression system (stat improvements based on XP gain)" },
                    { "item" : "Enemy AI behaviour (e.g. following pre-defined routes, custom chase and attacking behaviour)" },
                    { "item" : "A variety of enemy types built using a modular system" },
                    { "item" : "Modular weapon creation and pick-up system" }
                ],
                "imageSrc" : "./Images/RPG Sword Combat.gif"
            },
            {
                "subheading" : "Course Takeaways",
                "text" : "Completing the course helped to further improve my knowledge of design and programming patterns, which I have taken forward into future projects (e.g. VR Training House), enabling me to create optimised and maintainable code. It has also given me insight into developing a larger project and how to build strong foundational systems that effectively support future expansion.",
                "imageSrc" : "./Images/RPG Pickup.gif"
            }
        ]
    }
]

